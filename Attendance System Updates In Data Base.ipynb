{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "094ab1aa",
   "metadata": {},
   "source": [
    "# Attendance System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381d2ea",
   "metadata": {},
   "source": [
    "## 1. Training a New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69f4aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Your Name: Name\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "video=cv2.VideoCapture(0)\n",
    "facedetect=cv2.CascadeClassifier('data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "faces_data=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "name=input(\"Enter Your Name: \")\n",
    "\n",
    "while True:\n",
    "    ret,frame=video.read()\n",
    "    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces=facedetect.detectMultiScale(gray, 1.3 ,5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        crop_img=frame[y:y+h, x:x+w, :]\n",
    "        resized_img=cv2.resize(crop_img, (50,50))\n",
    "        if len(faces_data)<=100 and i%10==0:\n",
    "            faces_data.append(resized_img)\n",
    "        i=i+1\n",
    "        cv2.putText(frame, str(len(faces_data)), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (50,50,255), 1)\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (50,50,255), 1)\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==ord('q') or len(faces_data)==100:\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "faces_data=np.asarray(faces_data)\n",
    "faces_data=faces_data.reshape(100, -1)\n",
    "\n",
    "\n",
    "if 'names.pkl' not in os.listdir('data/'):\n",
    "    names=[name]*100\n",
    "    with open('data/names.pkl', 'wb') as f:\n",
    "        pickle.dump(names, f)\n",
    "else:\n",
    "    with open('data/names.pkl', 'rb') as f:\n",
    "        names=pickle.load(f)\n",
    "    names=names+[name]*100\n",
    "    with open('data/names.pkl', 'wb') as f:\n",
    "        pickle.dump(names, f)\n",
    "\n",
    "if 'faces_data.pkl' not in os.listdir('data/'):\n",
    "    with open('data/faces_data.pkl', 'wb') as f:\n",
    "        pickle.dump(faces_data, f)\n",
    "else:\n",
    "    with open('data/faces_data.pkl', 'rb') as f:\n",
    "        faces=pickle.load(f)\n",
    "    faces=np.append(faces, faces_data, axis=0)\n",
    "    with open('data/faces_data.pkl', 'wb') as f:\n",
    "        pickle.dump(faces, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c2427",
   "metadata": {},
   "source": [
    "## 2. Facial Recognization Attendance System Update In Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef165aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded attendance records: {'Name': datetime.datetime(1900, 1, 1, 15, 43, 39)}\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n",
      "Skipping attendance for Name, last recorded less than 10 minutes ago.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from win32com.client import Dispatch\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def speak(str1):\n",
    "    speak = Dispatch(\"SAPI.SpVoice\")\n",
    "    speak.Speak(str1)\n",
    "\n",
    "def load_attendance_records(filepath):\n",
    "    attendance_records = {}\n",
    "    try:\n",
    "        with open(filepath, 'r', newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                user = row['NAME']\n",
    "                last_time = datetime.strptime(row['TIME'], \"%H:%M:%S\")\n",
    "                attendance_records[user] = last_time\n",
    "    except FileNotFoundError:\n",
    "        print(\"No existing attendance file found. Starting fresh.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading attendance records: {e}\")\n",
    "    return attendance_records\n",
    "\n",
    "def append_attendance_record(filepath, name, time_str):\n",
    "    file_exists = os.path.isfile(filepath)\n",
    "    with open(filepath, \"a\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['NAME', 'TIME'])  # Write the header if the file does not exist\n",
    "        writer.writerow([name, time_str])\n",
    "\n",
    "# Initialize camera and classifiers\n",
    "video = cv2.VideoCapture(0)\n",
    "facedetect = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load data\n",
    "with open('data/names.pkl', 'rb') as w:\n",
    "    LABELS = pickle.load(w)\n",
    "with open('data/faces_data.pkl', 'rb') as f:\n",
    "    FACES = pickle.load(f)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(FACES, LABELS)\n",
    "\n",
    "imgBackground = cv2.imread(\"background.png\")\n",
    "\n",
    "# Load existing attendance records\n",
    "date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "attendance_file = f\"Attendance/Attendance_{date}.csv\"\n",
    "attendance_records = load_attendance_records(attendance_file)\n",
    "\n",
    "print(\"Loaded attendance records:\", attendance_records)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = facedetect.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    current_time = datetime.now().time()\n",
    "    for (x, y, w, h) in faces:\n",
    "        crop_img = frame[y:y+h, x:x+w]\n",
    "        resized_img = cv2.resize(crop_img, (50, 50)).flatten().reshape(1, -1)\n",
    "        output = knn.predict(resized_img)\n",
    "        label = str(output[0]) if output[0] in LABELS else \"Unknown\"\n",
    "        should_record = True\n",
    "\n",
    "        should_record = True  # Assume we should record the attendance\n",
    "\n",
    "        if label in attendance_records:\n",
    "            last_recorded_time = attendance_records[label].time()  # Extract time part\n",
    "            current_datetime = datetime.combine(datetime.today(), current_time)\n",
    "            last_recorded_datetime = datetime.combine(datetime.today(), last_recorded_time)\n",
    "        \n",
    "            time_diff_minutes = (current_datetime - last_recorded_datetime).total_seconds() / 60.0\n",
    "        \n",
    "            if time_diff_minutes < 10:\n",
    "                should_record = False\n",
    "        if should_record:\n",
    "            print(f\"Recording attendance for {label} at {current_time.strftime('%H:%M:%S')}\")\n",
    "            append_attendance_record(attendance_file, label, current_time.strftime(\"%H:%M:%S\"))\n",
    "            attendance_records[label] = current_time\n",
    "            # Now, update the Google Sheet\n",
    "            #update_google_sheet_from_csv(attendance_file)\n",
    "        else:\n",
    "            print(f\"Skipping attendance for {label}, last recorded less than 10 minutes ago.\")\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "    \n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = frame\n",
    "    cv2.imshow(\"Frame\", imgBackground)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('o'):\n",
    "        speak(\"Attendance Taken..\")\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a03a8",
   "metadata": {},
   "source": [
    "## 3. Loading CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d19881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>15:43:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NAME      TIME\n",
       "0  Name  15:43:39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./Attendance/Attendance_25-04-2024.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0ca43",
   "metadata": {},
   "source": [
    "## 4. Updating CSV File in MySQL Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "827f7ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're connected to database:  ('my_database',)\n",
      "Creating table....\n",
      "Table is created....\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector as mysql\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    conn = mysql.connect(host='localhost', database='my_database', user='root', password='*************') # tips\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        cursor.execute('DROP TABLE IF EXISTS data;') # tips_data\n",
    "        print('Creating table....')\n",
    "        # in the below line please pass the create table statement which you want #to create\n",
    "        #tips_data(columnname1 datatype,columnname2 datatype .....)\n",
    "        cursor.execute(\"CREATE TABLE data(name VARCHAR(255), time TIME)\")\n",
    "        print(\"Table is created....\")\n",
    "        #loop through the data frame\n",
    "        for i,row in data.iterrows():\n",
    "            #here %S means\n",
    "            # tips.tips_data\n",
    "            sql = \"INSERT INTO my_database.data VALUES (%s,%s)\" # how many columns are there that many %s\n",
    "            cursor.execute(sql, tuple(row))\n",
    "            #print(\"Record inserted\")\n",
    "            # the connection is not auto committed by default, so we must commit to save our changes\n",
    "            conn.commit()\n",
    "except Error as e:\n",
    "            print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40db58ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>0 days 15:43:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name            time\n",
       "0  Name 0 days 15:43:39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1=pd.read_sql(\"SELECT * FROM my_database.data\",conn)\n",
    "display(data1.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d9a37",
   "metadata": {},
   "source": [
    "# To Connect to GDrive Code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "643453b7",
   "metadata": {},
   "source": [
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "import csv\n",
    "\n",
    "# Replace with your JSON credentials and Google Sheet ID\n",
    "SERVICE_ACCOUNT_FILE = 'credentials.json'\n",
    "SPREADSHEET_ID = '1Sdufj3pbnIto-nu3dKSjwgLlj0y7A13vu48tKlkEZWs'\n",
    "\n",
    "# Define the scope and create credentials\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "credentials = Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "\n",
    "# Build the service\n",
    "service = build('sheets', 'v4', credentials=credentials)\n",
    "sheet = service.spreadsheets()\n",
    "\n",
    "def update_google_sheet_from_csv(csv_path):\n",
    "    with open(csv_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        values = list(reader)\n",
    "\n",
    "    body = {\n",
    "        'values': values\n",
    "    }\n",
    "    range_name = 'Sheet1'  # Adjust if using a different sheet name\n",
    "    result = sheet.values().update(\n",
    "        spreadsheetId=SPREADSHEET_ID, range=range_name,\n",
    "        valueInputOption='RAW', body=body).execute()\n",
    "    print(f\"{result.get('updatedCells')} cells updated.\")\n",
    "\n",
    "# Example usage\n",
    "date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "attendance_file = f\"Attendance/Attendance_{date}.csv\"\n",
    "update_google_sheet_from_csv(attendance_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
